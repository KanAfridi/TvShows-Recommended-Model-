{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2b4fc06-e418-43fa-b05e-5e79c6e70309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings = \"ignore_warnings\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a166ae5f-bd4e-4cdd-b418-6c938538f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv(r\"E:/documents/python practice/new/tvs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d17160f2-969c-4457-8379-5933eba028d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>created_by</th>\n",
       "      <th>first_air_date</th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>in_production</th>\n",
       "      <th>last_air_date</th>\n",
       "      <th>name</th>\n",
       "      <th>number_of_episodes</th>\n",
       "      <th>number_of_seasons</th>\n",
       "      <th>...</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_name</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6457d26c7b901e08b141869d</td>\n",
       "      <td>[]</td>\n",
       "      <td>1996-10-09</td>\n",
       "      <td>[{\"id\":35,\"name\":\"Comedy\",\"_id\":{\"$oid\":\"6457d...</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>How do you like Wednesday?</td>\n",
       "      <td>568.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>ja</td>\n",
       "      <td>水曜どうでしょう</td>\n",
       "      <td>How do you like Wednesday? was a Japanese tele...</td>\n",
       "      <td>21.207</td>\n",
       "      <td>/i2MwS6U0XzD8ad6aS3HiTNKz8ov.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>Returning Series</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6457d26c7b901e08b141867a</td>\n",
       "      <td>[{\"id\":19303,\"name\":\"Kevin Smith\",\"_id\":{\"$oid...</td>\n",
       "      <td>2000-05-31</td>\n",
       "      <td>[{\"id\":16,\"name\":\"Animation\",\"_id\":{\"$oid\":\"64...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>2002-12-22</td>\n",
       "      <td>Clerks</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>Clerks</td>\n",
       "      <td>The continuing adventures of store clerks Dant...</td>\n",
       "      <td>10.620</td>\n",
       "      <td>/xunXvzFlkf1GGgMkCySA9CCFumB.jpg</td>\n",
       "      <td>[{\"id\":1558,\"name\":\"Touchstone Television\",\"lo...</td>\n",
       "      <td>Canceled</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.897</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  6457d26c7b901e08b141869d   \n",
       "1  6457d26c7b901e08b141867a   \n",
       "\n",
       "                                          created_by first_air_date  \\\n",
       "0                                                 []     1996-10-09   \n",
       "1  [{\"id\":19303,\"name\":\"Kevin Smith\",\"_id\":{\"$oid...     2000-05-31   \n",
       "\n",
       "                                              genres  id  in_production  \\\n",
       "0  [{\"id\":35,\"name\":\"Comedy\",\"_id\":{\"$oid\":\"6457d...  13           True   \n",
       "1  [{\"id\":16,\"name\":\"Animation\",\"_id\":{\"$oid\":\"64...   2          False   \n",
       "\n",
       "  last_air_date                        name  number_of_episodes  \\\n",
       "0    2022-02-16  How do you like Wednesday?               568.0   \n",
       "1    2002-12-22                      Clerks                 6.0   \n",
       "\n",
       "   number_of_seasons  ... original_language original_name  \\\n",
       "0                  4  ...                ja      水曜どうでしょう   \n",
       "1                  1  ...                en        Clerks   \n",
       "\n",
       "                                            overview popularity  \\\n",
       "0  How do you like Wednesday? was a Japanese tele...     21.207   \n",
       "1  The continuing adventures of store clerks Dant...     10.620   \n",
       "\n",
       "                        poster_path  \\\n",
       "0  /i2MwS6U0XzD8ad6aS3HiTNKz8ov.jpg   \n",
       "1  /xunXvzFlkf1GGgMkCySA9CCFumB.jpg   \n",
       "\n",
       "                                production_companies            status  \\\n",
       "0                                                 []  Returning Series   \n",
       "1  [{\"id\":1558,\"name\":\"Touchstone Television\",\"lo...          Canceled   \n",
       "\n",
       "  tagline vote_average  vote_count  \n",
       "0     NaN        9.200           2  \n",
       "1     NaN        6.897          78  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e6679a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb49a976-67da-450d-9f29-d63c010de898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'created_by', 'first_air_date', 'genres', 'id', 'in_production',\n",
       "       'last_air_date', 'name', 'number_of_episodes', 'number_of_seasons',\n",
       "       'origin_country', 'original_language', 'original_name', 'overview',\n",
       "       'popularity', 'poster_path', 'production_companies', 'status',\n",
       "       'tagline', 'vote_average', 'vote_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43307d4c-6918-40c3-b60c-5528f5aeb30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150802 entries, 0 to 150801\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   _id                   150802 non-null  object \n",
      " 1   created_by            150802 non-null  object \n",
      " 2   first_air_date        119932 non-null  object \n",
      " 3   genres                150802 non-null  object \n",
      " 4   id                    150802 non-null  int64  \n",
      " 5   in_production         150802 non-null  bool   \n",
      " 6   last_air_date         122108 non-null  object \n",
      " 7   name                  150796 non-null  object \n",
      " 8   number_of_episodes    150168 non-null  float64\n",
      " 9   number_of_seasons     150802 non-null  int64  \n",
      " 10  origin_country        150802 non-null  object \n",
      " 11  original_language     150802 non-null  object \n",
      " 12  original_name         150796 non-null  object \n",
      " 13  overview              84623 non-null   object \n",
      " 14  popularity            150802 non-null  float64\n",
      " 15  poster_path           94927 non-null   object \n",
      " 16  production_companies  150802 non-null  object \n",
      " 17  status                150802 non-null  object \n",
      " 18  tagline               4564 non-null    object \n",
      " 19  vote_average          150802 non-null  float64\n",
      " 20  vote_count            150802 non-null  int64  \n",
      "dtypes: bool(1), float64(3), int64(3), object(14)\n",
      "memory usage: 23.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6173a98a-b68d-42ea-a1b0-a05cd5d1b996",
   "metadata": {},
   "source": [
    "- First of all i'm gonna delte some columns which is not import for our model\n",
    "- i want just some columns like genres overview, tagline, name, and maybe production_com\n",
    "- but before that i wanna i wanna drop every single null values in a column which is import for our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82a14f8",
   "metadata": {},
   "source": [
    "***Actully i have tried to make a model with 28k dimensions but i was getting lots of error and the size of the data was aboutt 6 GB so i reduce the size of the data and i just took the most import and famous tv shows from the data and applyy the model on it and now it's size about 550 Mbs:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b477883",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['_id', 'first_air_date', 'in_production',\n",
    "       'last_air_date', 'number_of_episodes', 'number_of_seasons',\n",
    "       'original_name',\n",
    "       'popularity', 'status',\n",
    "      'vote_average', 'tagline']\n",
    "\n",
    "df = df.drop(columns = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52c7991",
   "metadata": {},
   "source": [
    "- **There is some empty list where is nothing in these columns so let's find out how much theyyy are in each columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85887b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32601"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['created_by'].map(lambda x: np.nan if x == [] or x== '[]' else x).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27520c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150802, 10)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "366d4ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_by 32601\n",
      "genres 88497\n",
      "id 150802\n",
      "name 150796\n",
      "origin_country 118147\n",
      "original_language 150802\n",
      "overview 84623\n",
      "poster_path 94927\n",
      "production_companies 52049\n",
      "vote_count 150802\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    empt_list = df[col].map(lambda x: np.nan if x == [] or x== '[]' else x).count()\n",
    "    print(col,empt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c59a9f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will transfer both to nan\n",
    "df = df.map(lambda x: np.nan if x == [] or x == \"[]\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7fab7b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_by              118201\n",
       "genres                   62305\n",
       "id                           0\n",
       "name                         6\n",
       "origin_country           32655\n",
       "original_language            0\n",
       "overview                 66179\n",
       "poster_path              55875\n",
       "production_companies     98753\n",
       "vote_count                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32a43a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i want to drop all the null rows espcially if it's in the following columns because the rest i will delete even though if it's \\\n",
    "    # not empty because only we need textiual data for our model\n",
    "col_list = ['created_by', 'name', 'genres', 'origin_country', 'original_language', 'overview', 'poster_path', 'production_companies']\n",
    "df = df.dropna(subset= col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc3a10c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now i want to make it more smaller i mean less than 10k so i would perform filter on vote_count collumn actually \\\n",
    "    # i want to drop the values if it's less than 2 mean 200 vote_count\n",
    "df = df[df['vote_count'] >2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5cf2266b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8536, 10)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1de5ee52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_by              0\n",
       "genres                  0\n",
       "id                      0\n",
       "name                    0\n",
       "origin_country          0\n",
       "original_language       0\n",
       "overview                0\n",
       "poster_path             0\n",
       "production_companies    0\n",
       "vote_count              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6a2bf5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now i wanna drop null values\n",
    "df.dropna(inplace=True)\n",
    "df = df.drop(columns= 'vote_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d01683-4455-42f3-a9e4-b915076f7f7c",
   "metadata": {},
   "source": [
    "## Function to fetch the name from the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "654f1a19-2986-4707-9d43-d2ab16f61687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b7d645f2-5ec9-4991-9f9f-f6806fe984ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def fetch_genres(obj):\n",
    "    name_list = []  \n",
    "    try:\n",
    "        # Parse the JSON string\n",
    "        data = json.loads(obj)\n",
    "        # Extract names\n",
    "        for i in data:\n",
    "            name_list.append(i['name'])\n",
    "    except (json.JSONDecodeError, KeyError, TypeError):\n",
    "        return None\n",
    "    return name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f16a28a7-e961-48c8-8737-9d59e3301c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                                       [Animation, Comedy]\n",
       "3                                                    [Kids]\n",
       "5                                                  [Comedy]\n",
       "6         [Kids, Animation, Action & Adventure, Sci-Fi &...\n",
       "8                                     [Drama, Soap, Comedy]\n",
       "                                ...                        \n",
       "148489                                              [Drama]\n",
       "148490                                       [Drama, Crime]\n",
       "148809                                              [Drama]\n",
       "149054                                    [Comedy, Mystery]\n",
       "149653                      [Drama, Family, Crime, Mystery]\n",
       "Name: genres, Length: 8536, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genres'].apply(fetch_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d44bbfe-b57c-4019-b139-278b7f379bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to save the clean column\n",
    "df['genres'] = df['genres'].apply(fetch_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3281ec3-222f-42dd-9fe0-355f23a7a537",
   "metadata": {},
   "source": [
    "**Now let's apply the same function on production_companies if it's work or no?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6a85d7be-6d5f-4911-9346-b326bc35b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the fetch_json on companies column\n",
    "df['production_companies'] = df['production_companies'].apply(fetch_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2d4aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_by'] = df['created_by'].apply(fetch_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "972848b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_by</th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>production_companies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Kevin Smith, Scott Mosier, David Mandel]</td>\n",
       "      <td>[Animation, Comedy]</td>\n",
       "      <td>2</td>\n",
       "      <td>Clerks</td>\n",
       "      <td>[\"US\"]</td>\n",
       "      <td>en</td>\n",
       "      <td>The continuing adventures of store clerks Dant...</td>\n",
       "      <td>/xunXvzFlkf1GGgMkCySA9CCFumB.jpg</td>\n",
       "      <td>[Touchstone Television, View Askew Productions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Fred Rogers]</td>\n",
       "      <td>[Kids]</td>\n",
       "      <td>15</td>\n",
       "      <td>Mister Rogers' Neighborhood</td>\n",
       "      <td>[\"US\"]</td>\n",
       "      <td>en</td>\n",
       "      <td>Mister Rogers' Neighborhood is an American chi...</td>\n",
       "      <td>/4Gz46uJg6MFaM4xeblbVNSxCyTr.jpg</td>\n",
       "      <td>[WQED, Small World Enterprises, Family Communi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Bill Bixby]</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>18</td>\n",
       "      <td>W*A*L*T*E*R</td>\n",
       "      <td>[\"US\"]</td>\n",
       "      <td>en</td>\n",
       "      <td>W*A*L*T*E*R is a pilot for a spin-off of M*A*S...</td>\n",
       "      <td>/fwSw4fl08MVl5w6Q9lVUGIFkZQ2.jpg</td>\n",
       "      <td>[20th Century Fox Television]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[George Lucas, Ben Burtt, Clive A. Smith, Raym...</td>\n",
       "      <td>[Kids, Animation, Action &amp; Adventure, Sci-Fi &amp;...</td>\n",
       "      <td>25</td>\n",
       "      <td>Star Wars: Droids</td>\n",
       "      <td>[\"CA\",\"US\"]</td>\n",
       "      <td>en</td>\n",
       "      <td>An animated television series that features th...</td>\n",
       "      <td>/b3gsZSTauRBJDJvWCbD9oVAsFe1.jpg</td>\n",
       "      <td>[Lucasfilm Animation, Lucasfilm Ltd.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Gail Parent, Norman Lear, Ann Marcus, Jerry A...</td>\n",
       "      <td>[Drama, Soap, Comedy]</td>\n",
       "      <td>29</td>\n",
       "      <td>Mary Hartman, Mary Hartman</td>\n",
       "      <td>[\"US\"]</td>\n",
       "      <td>en</td>\n",
       "      <td>In the fictional town of Fernwood, Ohio, subur...</td>\n",
       "      <td>/O1bcYEBW8v7JOMNVpYOBTL6PjL.jpg</td>\n",
       "      <td>[TAT Communications Company]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          created_by  \\\n",
       "1          [Kevin Smith, Scott Mosier, David Mandel]   \n",
       "3                                      [Fred Rogers]   \n",
       "5                                       [Bill Bixby]   \n",
       "6  [George Lucas, Ben Burtt, Clive A. Smith, Raym...   \n",
       "8  [Gail Parent, Norman Lear, Ann Marcus, Jerry A...   \n",
       "\n",
       "                                              genres  id  \\\n",
       "1                                [Animation, Comedy]   2   \n",
       "3                                             [Kids]  15   \n",
       "5                                           [Comedy]  18   \n",
       "6  [Kids, Animation, Action & Adventure, Sci-Fi &...  25   \n",
       "8                              [Drama, Soap, Comedy]  29   \n",
       "\n",
       "                          name origin_country original_language  \\\n",
       "1                       Clerks         [\"US\"]                en   \n",
       "3  Mister Rogers' Neighborhood         [\"US\"]                en   \n",
       "5                  W*A*L*T*E*R         [\"US\"]                en   \n",
       "6            Star Wars: Droids    [\"CA\",\"US\"]                en   \n",
       "8   Mary Hartman, Mary Hartman         [\"US\"]                en   \n",
       "\n",
       "                                            overview  \\\n",
       "1  The continuing adventures of store clerks Dant...   \n",
       "3  Mister Rogers' Neighborhood is an American chi...   \n",
       "5  W*A*L*T*E*R is a pilot for a spin-off of M*A*S...   \n",
       "6  An animated television series that features th...   \n",
       "8  In the fictional town of Fernwood, Ohio, subur...   \n",
       "\n",
       "                        poster_path  \\\n",
       "1  /xunXvzFlkf1GGgMkCySA9CCFumB.jpg   \n",
       "3  /4Gz46uJg6MFaM4xeblbVNSxCyTr.jpg   \n",
       "5  /fwSw4fl08MVl5w6Q9lVUGIFkZQ2.jpg   \n",
       "6  /b3gsZSTauRBJDJvWCbD9oVAsFe1.jpg   \n",
       "8   /O1bcYEBW8v7JOMNVpYOBTL6PjL.jpg   \n",
       "\n",
       "                                production_companies  \n",
       "1  [Touchstone Television, View Askew Productions...  \n",
       "3  [WQED, Small World Enterprises, Family Communi...  \n",
       "5                      [20th Century Fox Television]  \n",
       "6              [Lucasfilm Animation, Lucasfilm Ltd.]  \n",
       "8                       [TAT Communications Company]  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5ab030df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove the quotation from the list\n",
    "# df['origin_country'] = df['origin_country'].apply(lambda x: ast.literal_eval(x))\n",
    "df['origin_country'] = df['origin_country'].apply(lambda x: x.strip('[]').replace('\"', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57dc0a7d-b2f1-4780-afec-696531c239f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i want this column to be in a list form too\n",
    "df['overview'] = df['overview'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca692c-c56a-4e41-b146-4779ddfcbac9",
   "metadata": {},
   "source": [
    "## Removing spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "430eba71-ff08-4dc1-8fc2-755d9826622b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                                       [Animation, Comedy]\n",
       "3                                                    [Kids]\n",
       "5                                                  [Comedy]\n",
       "6         [Kids, Animation, Action&Adventure, Sci-Fi&Fan...\n",
       "8                                     [Drama, Soap, Comedy]\n",
       "                                ...                        \n",
       "148489                                              [Drama]\n",
       "148490                                       [Drama, Crime]\n",
       "148809                                              [Drama]\n",
       "149054                                    [Comedy, Mystery]\n",
       "149653                      [Drama, Family, Crime, Mystery]\n",
       "Name: genres, Length: 8536, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No spaces between words\n",
    "df['genres'].map(lambda x: [i.replace(\" \", \"\") for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "93265f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_by</th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>production_companies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Kevin Smith, Scott Mosier, David Mandel]</td>\n",
       "      <td>[Animation, Comedy]</td>\n",
       "      <td>2</td>\n",
       "      <td>Clerks</td>\n",
       "      <td>US</td>\n",
       "      <td>en</td>\n",
       "      <td>[The, continuing, adventures, of, store, clerk...</td>\n",
       "      <td>/xunXvzFlkf1GGgMkCySA9CCFumB.jpg</td>\n",
       "      <td>[Touchstone Television, View Askew Productions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Fred Rogers]</td>\n",
       "      <td>[Kids]</td>\n",
       "      <td>15</td>\n",
       "      <td>Mister Rogers' Neighborhood</td>\n",
       "      <td>US</td>\n",
       "      <td>en</td>\n",
       "      <td>[Mister, Rogers', Neighborhood, is, an, Americ...</td>\n",
       "      <td>/4Gz46uJg6MFaM4xeblbVNSxCyTr.jpg</td>\n",
       "      <td>[WQED, Small World Enterprises, Family Communi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Bill Bixby]</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>18</td>\n",
       "      <td>W*A*L*T*E*R</td>\n",
       "      <td>US</td>\n",
       "      <td>en</td>\n",
       "      <td>[W*A*L*T*E*R, is, a, pilot, for, a, spin-off, ...</td>\n",
       "      <td>/fwSw4fl08MVl5w6Q9lVUGIFkZQ2.jpg</td>\n",
       "      <td>[20th Century Fox Television]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[George Lucas, Ben Burtt, Clive A. Smith, Raym...</td>\n",
       "      <td>[Kids, Animation, Action &amp; Adventure, Sci-Fi &amp;...</td>\n",
       "      <td>25</td>\n",
       "      <td>Star Wars: Droids</td>\n",
       "      <td>CA,US</td>\n",
       "      <td>en</td>\n",
       "      <td>[An, animated, television, series, that, featu...</td>\n",
       "      <td>/b3gsZSTauRBJDJvWCbD9oVAsFe1.jpg</td>\n",
       "      <td>[Lucasfilm Animation, Lucasfilm Ltd.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Gail Parent, Norman Lear, Ann Marcus, Jerry A...</td>\n",
       "      <td>[Drama, Soap, Comedy]</td>\n",
       "      <td>29</td>\n",
       "      <td>Mary Hartman, Mary Hartman</td>\n",
       "      <td>US</td>\n",
       "      <td>en</td>\n",
       "      <td>[In, the, fictional, town, of, Fernwood,, Ohio...</td>\n",
       "      <td>/O1bcYEBW8v7JOMNVpYOBTL6PjL.jpg</td>\n",
       "      <td>[TAT Communications Company]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          created_by  \\\n",
       "1          [Kevin Smith, Scott Mosier, David Mandel]   \n",
       "3                                      [Fred Rogers]   \n",
       "5                                       [Bill Bixby]   \n",
       "6  [George Lucas, Ben Burtt, Clive A. Smith, Raym...   \n",
       "8  [Gail Parent, Norman Lear, Ann Marcus, Jerry A...   \n",
       "\n",
       "                                              genres  id  \\\n",
       "1                                [Animation, Comedy]   2   \n",
       "3                                             [Kids]  15   \n",
       "5                                           [Comedy]  18   \n",
       "6  [Kids, Animation, Action & Adventure, Sci-Fi &...  25   \n",
       "8                              [Drama, Soap, Comedy]  29   \n",
       "\n",
       "                          name origin_country original_language  \\\n",
       "1                       Clerks             US                en   \n",
       "3  Mister Rogers' Neighborhood             US                en   \n",
       "5                  W*A*L*T*E*R             US                en   \n",
       "6            Star Wars: Droids          CA,US                en   \n",
       "8   Mary Hartman, Mary Hartman             US                en   \n",
       "\n",
       "                                            overview  \\\n",
       "1  [The, continuing, adventures, of, store, clerk...   \n",
       "3  [Mister, Rogers', Neighborhood, is, an, Americ...   \n",
       "5  [W*A*L*T*E*R, is, a, pilot, for, a, spin-off, ...   \n",
       "6  [An, animated, television, series, that, featu...   \n",
       "8  [In, the, fictional, town, of, Fernwood,, Ohio...   \n",
       "\n",
       "                        poster_path  \\\n",
       "1  /xunXvzFlkf1GGgMkCySA9CCFumB.jpg   \n",
       "3  /4Gz46uJg6MFaM4xeblbVNSxCyTr.jpg   \n",
       "5  /fwSw4fl08MVl5w6Q9lVUGIFkZQ2.jpg   \n",
       "6  /b3gsZSTauRBJDJvWCbD9oVAsFe1.jpg   \n",
       "8   /O1bcYEBW8v7JOMNVpYOBTL6PjL.jpg   \n",
       "\n",
       "                                production_companies  \n",
       "1  [Touchstone Television, View Askew Productions...  \n",
       "3  [WQED, Small World Enterprises, Family Communi...  \n",
       "5                      [20th Century Fox Television]  \n",
       "6              [Lucasfilm Animation, Lucasfilm Ltd.]  \n",
       "8                       [TAT Communications Company]  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1370c125-e4ab-4ea0-9b9f-4c57ab373a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No spaces between words between each word\n",
    "df['production_companies'] = df['production_companies'].map(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "df['genres'] = df['genres'].map(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "df['created_by'] = df['created_by'].map(lambda x: [i.replace(\" \", \"\") for i in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eb7611c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df['created_by'].iloc[1]))  # Check type of the first value\n",
    "print(type(df['genres'].iloc[1]))      # Check type of the first value\n",
    "print(type(df['origin_country'].iloc[1]))  # Check type of the first value\n",
    "print(type(df['original_language'].iloc[1]))  \n",
    "print(type(df['overview'].iloc[1]))  \n",
    "print(type(df['production_companies'].iloc[1]))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "75595900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         [en]\n",
       "3         [en]\n",
       "5         [en]\n",
       "6         [en]\n",
       "8         [en]\n",
       "          ... \n",
       "148489    [es]\n",
       "148490    [nl]\n",
       "148809    [tr]\n",
       "149054    [hi]\n",
       "149653    [zh]\n",
       "Name: original_language, Length: 8536, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # removing the quotes from the original language and change it to list\n",
    "df['original_language'].apply(lambda x: x.split(\", \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "372491d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the quotes from the original country and change it to list same with language\n",
    "df['origin_country'] = df['origin_country'].apply(lambda x: x.replace('\"', '').split())\n",
    "df['original_language'] = df['original_language'].apply(lambda x: x.split(\", \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "baaa7828-626c-4db8-adf9-73b9f99e1a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i make a new column to combine everything together\n",
    "df['tags'] = df['genres'] + df['origin_country'] + df['origin_country'] + df['overview'] + df['production_companies'] + df['created_by']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dd179266-d4ed-4cd7-bcb5-0aac9bc89237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fc94838f-51df-42fc-bcaa-ac21f5018704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df is now ready for more process \n",
    "new_df = df[['id', 'name', 'tags', 'poster_path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d2dbaa8a-f545-46d5-b4d0-b84c3fcdca7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JASIM\\AppData\\Local\\Temp\\ipykernel_15516\\2263816752.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags'] = new_df['tags'].map(lambda x: \" \".join(x))\n"
     ]
    }
   ],
   "source": [
    "# Now removing the list from the tags column\n",
    "new_df['tags'] = new_df['tags'].map(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a87c7606-1661-48ba-bdb1-ca2c6d5a43bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JASIM\\AppData\\Local\\Temp\\ipykernel_15516\\184896880.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags'] = new_df['tags'].map(lambda x: x.lower())\n"
     ]
    }
   ],
   "source": [
    "# Change the text into lower case\n",
    "new_df['tags'] = new_df['tags'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8221ef08",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "366b9169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "pr = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5b835c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function to apply the stemmer to the features tags\n",
    "def stemer(text):\n",
    "    list = []\n",
    "\n",
    "    for i in text.split():\n",
    "        list.append(pr.stem(i))\n",
    "    return \" \".join(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "47dc31fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       anim comedi us us the continu adventur of stor...\n",
       "1       kid us us mister rogers' neighborhood is an am...\n",
       "2       comedi us us w*a*l*t*e*r is a pilot for a spin...\n",
       "3       kid anim action&adventur sci-fi&fantasi ca,u c...\n",
       "4       drama soap comedi us us in the fiction town of...\n",
       "                              ...                        \n",
       "8531    drama ar ar no one can and should live without...\n",
       "8532    drama crime be be when a prodig son send hi fa...\n",
       "8533    drama tr tr the stori revolv around the love t...\n",
       "8534    comedi mysteri in in a rebelli vampir with a b...\n",
       "8535    drama famili crime mysteri cn cn the stori rev...\n",
       "Name: tags, Length: 8536, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['tags'].apply(stemer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2127a74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JASIM\\AppData\\Local\\Temp\\ipykernel_15516\\71712778.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags'] = new_df['tags'].apply(stemer)\n"
     ]
    }
   ],
   "source": [
    "new_df['tags'] = new_df['tags'].apply(stemer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba4dfa9-22d5-4678-b06c-f519d6310f87",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b5155eef-f051-4b9b-a9c7-337c958054ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# couunt vectorizer will change the words to numbers into numpyy array\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=4000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d0c0ed4d-607f-4c16-8fe2-4e7e767bd647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# savving in variable \n",
    "vectors = cv.fit_transform(new_df['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55f18cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014',\n",
       "       '2016', '2017', '2022', '20th', '20thcenturyfoxtelevis',\n",
       "       '20thtelevis', '20thtelevisionanim', '21', '21st', '22', '23',\n",
       "       '24', '25', '26', '27', '28', '29', '30', '30s', '31', '32', '35'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()[70:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e1596042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8536, 4000)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57482873-ea41-4348-b614-39924d54182f",
   "metadata": {},
   "source": [
    "## Cosine Similarity content based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1abd37-49a1-4eb6-8cf9-0b96dd43cfe0",
   "metadata": {},
   "source": [
    "okayy now we are gonna apply the technique after all that how much the each tv shows or similar to ech other  is far from each other in dimension we can use two of them cosign similirty or uclidient but becuaae we have hight dimension so cosign simility is mroe better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "228afb46-1ad5-4cf2-bbdd-1611cde6de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_score = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "66f92f95-8947-4cbf-9b96-b9d43cb2aaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2958"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[new_df['name'] == 'Vikings'].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3a98ed94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8536, 8536)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5db9e9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the similarity matrix: 555.90 MB\n"
     ]
    }
   ],
   "source": [
    "data_sizes = similarity_score.nbytes/ ( 1024**2)\n",
    "\n",
    "print(f'Size of the similarity matrix: {data_sizes:.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f6ec34",
   "metadata": {},
   "source": [
    "## Function for tv Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d7894c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2958"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting index by name\n",
    "new_df[new_df['name'] == \"Vikings\"].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1cea8499-dcee-4e77-b71b-b3a0575d60d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(966, 0.4262183570801332),\n",
       " (150, 0.41316814406864993),\n",
       " (1925, 0.40459194096600426),\n",
       " (851, 0.4004906973834362),\n",
       " (830, 0.39977519855091365)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(enumerate(similarity_score[1])), reverse=True, key= lambda x: x[1])[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d992c834-5b22-4d57-a60a-968288aea2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_similarity(series):\n",
    "    series_index = new_df[new_df['name'] == series].index[0]\n",
    "    similarity = similarity_score[series_index]\n",
    "    five_similar = sorted(list(enumerate(similarity)), reverse=True, key= lambda x: x[1])[1:6]\n",
    "    for i, score in five_similar:\n",
    "        name = new_df.loc[i]['name']\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "96c06e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Empire\n",
      "Baa Baa Black Sheep\n",
      "Slugterra\n",
      "The Legend of El Cid\n",
      "Big Wolf on Campus\n"
     ]
    }
   ],
   "source": [
    "show_similarity('Vikings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0885a3-87e7-47d5-9e04-b6073304c34c",
   "metadata": {},
   "source": [
    "i make a function where we are gonna get the 5 or 6 similiar series to the specific tv shows so \n",
    "first of all i filter based on seriees name and get their index \n",
    "first of all i get one values in similarity and then i use enumerate function because it will keep the index and the similirtyyy both other wise if directly sort the values it will disturb the index of all series so thats why then we just sort in decending order based on score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f073a8ab",
   "metadata": {},
   "source": [
    "### Actually i want to reduce the data becasue it's too larger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cf7744",
   "metadata": {},
   "source": [
    "- **i wanted to make a larger tv shows recommened system but i got an error because it was too larger**\n",
    "\n",
    "- **I'm gonna use cosine similarity and reduce the data size**\n",
    "\n",
    " - actually i'll reduce the data size by the vote count to get the most famous tv shows so it will be better because most of the people might know about this kind of tv shows so i'll edit the data from the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6136b2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the similarity matrix: 6466.87 MB\n"
     ]
    }
   ],
   "source": [
    "data_size = similarity_score.nbytes/ ( 1024**2)\n",
    "print(f'Size of the similarity matrix: {data_size:.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6377970",
   "metadata": {},
   "source": [
    "**Now i'll apply the process again in some cell**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df30253b",
   "metadata": {},
   "source": [
    "i would remove the data if the vote count is less than 20 butt important first of all i'll remove the data if import columns is null in it you might think the vote count is too low but actually it's not because even the most famous shows in this dataset like this according to my own research  the data vote count is 100 times less so if you wanna get real resurlt you have to do this (vote_count * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b18883",
   "metadata": {},
   "source": [
    "- *i want to drop all the null rows espcially if it's in the following columns because the rest i will delete even though if it's not empty because only we need textiual data for our model*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec0ba4-c3c6-4391-9cec-d9e66a8ee2d9",
   "metadata": {},
   "source": [
    "## Saving the model and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae831622",
   "metadata": {},
   "source": [
    "***actually the data is so big so it's hard to save with pickle or joblic etc so i use h5py after my research but still i was getting an issues in streamlit so i reduce the size of the data and then i make it 550 mbs but before it was more than 6 GB***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c664dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('similarity_file.pkl', 'wb') as file:\n",
    "    pickle.dump(similarity_score, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2357c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data.pkl', 'wb') as file:\n",
    "    pickle.dump(new_df, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
